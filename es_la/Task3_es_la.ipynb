{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea 3: utilizar Amazon Bedrock para responder a preguntas\n",
    "\n",
    "En este cuaderno, aprenderá a utilizar el modelo Bedrock Titan para proporcionar respuestas informativas a las consultas; para ello, deberá enviar la solicitud con todo el contexto pertinente al modelo y esperar la respuesta, lo que aborda el desafío de que el modelo devuelva respuestas fácticas a las preguntas sin necesidad de preparar e indexar los documentos con anticipación.\n",
    "\n",
    "Este cuaderno simula lo que haría la **generación aumentada por recuperación (RAG)**, pero en realidad no utiliza RAG. Este enfoque funciona con documentos cortos o aplicaciones únicas. Es posible que no responda a preguntas a nivel empresarial, ya que allí los documentos empresariales grandes no caben en la petición que se envía al modelo.\n",
    "\n",
    "La tarea de respuesta a preguntas **(Question Answering, QA)** es importante, ya que implica la extracción de respuestas en relación con consultas objetivas planteadas en lenguaje natural. En general, el sistema de QA procesa una consulta frente a una base de conocimiento que contiene datos estructurados o no estructurados y genera una respuesta con información precisa. Garantizar una alta exactitud es clave para desarrollar un sistema de respuesta a preguntas que sea útil, fiable y de confianza, en especial en lo que respecta a los casos prácticos empresariales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Situación\n",
    "\n",
    "Intenta modelar una situación en AnyCompany y pide al modelo de respuesta a preguntas que proporcione información acerca del cambio de neumáticos de un modelo de vehículo específico que fabrican. Primero, consulta el modelo con un enfoque \"sin entrenamiento previo\" para ver si puede proporcionar respuestas adecuadas en función de sus datos de entrenamiento únicamente.\n",
    "\n",
    "Sin embargo, se da cuenta de que el modelo parece estar \"alucinando\" con respuestas más genéricas, como se demuestra cuando prueba con un modelo de vehículo falso y obtiene respuestas similares. Esto implica la necesidad de aumentar el entrenamiento del modelo con los manuales de vehículos reales de Empresa de Ejemplo para dar detalles sobre los neumáticos de cada modelo.\n",
    "\n",
    "En este laboratorio, simulará un enfoque de \"generación aumentada por recuperación\" (RAG) sin datos externos. Proporcionará un extracto detallado del manual en el que se explica cómo cambiar los neumáticos del vehículo Modelo Z de AnyCompany. Comprueba si el modelo ahora puede dar una respuesta precisa y personalizada que aproveche este contenido de ejemplo contextualizado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarea 3.1: configuración del entorno\n",
    "\n",
    "En esta tarea, establecerá el entorno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#ignore warnings and create a service client by name using the default session.\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import boto3\n",
    "import botocore\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "module_path = \"..\"\n",
    "sys.path.append(os.path.abspath(module_path))\n",
    "bedrock_client = boto3.client('bedrock-runtime',region_name=os.environ.get(\"AWS_DEFAULT_REGION\", None))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarea 3.2: preguntas y respuestas con el conocimiento del modelo\n",
    "En esta sección, se intenta utilizar un modelo que proporciona el servicio Bedrock para responder a preguntas a partir del conocimiento obtenido durante la fase de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta tarea, utilizará el método invoke_model() del cliente Amazon Bedrock. Los parámetros obligatorios para utilizar este método son modelId, que representa el ARN del modelo de Amazon Bedrock, y body, que es la petición de la tarea.\n",
    "\n",
    "La petición body cambia en función del proveedor del modelo fundacional que seleccione. Esto se analizará en detalle a continuación.\n",
    "\n",
    "```json\n",
    "{\n",
    "   modelId= model_id,\n",
    "   contentType= \"application/json\",\n",
    "   accept= \"application/json\",\n",
    "   body=body\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "Se intenta utilizar los modelos que proporciona el servicio Bedrock para responder a preguntas a partir del conocimiento obtenido durante la fase de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_data = \"\"\"You are an helpful assistant. Answer questions in a concise way. If you are unsure about the\n",
    "answer say 'I am unsure'\n",
    "\n",
    "Question: How can I fix a flat tire on my AnyCompany AC8?\n",
    "Answer:\"\"\"\n",
    "parameters = {\n",
    "    \"maxTokenCount\":512,\n",
    "    \"stopSequences\":[],\n",
    "    \"temperature\":0,\n",
    "    \"topP\":0.9\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarea 3.3: invocar el modelo en el cuerpo JSON para generar la respuesta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#model configuration\n",
    "body = json.dumps({\"inputText\": prompt_data, \"textGenerationConfig\": parameters})\n",
    "modelId = \"amazon.titan-text-express-v1\"  # change this to use a different version from the model provider\n",
    "accept = \"application/json\"\n",
    "contentType = \"application/json\"\n",
    "try:\n",
    "    \n",
    "    response = bedrock_client.invoke_model(\n",
    "        body=body, modelId=modelId, accept=accept, contentType=contentType\n",
    "    )\n",
    "    response_body = json.loads(response.get(\"body\").read())\n",
    "    answer = response_body.get(\"results\")[0].get(\"outputText\")\n",
    "    print(answer.strip())\n",
    "\n",
    "except botocore.exceptions.ClientError as error:\n",
    "    if  error.response['Error']['Code'] == 'AccessDeniedException':\n",
    "        print(f\"\\x1b[41m{error.response['Error']['Message']}\\\n",
    "        \\nTo troubeshoot this issue please refer to the following resources.\\\n",
    "         \\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/troubleshoot_access-denied.html\\\n",
    "         \\nhttps://docs.aws.amazon.com/bedrock/latest/userguide/security-iam.html\\x1b[0m\\n\")      \n",
    "        class StopExecution(ValueError):\n",
    "            def _render_traceback_(self):\n",
    "                pass\n",
    "        raise StopExecution        \n",
    "    else:\n",
    "        raise error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "El modelo ofrece una respuesta en la que se detalla el proceso de cambio de un neumático desinflado en un automóvil, pero esa misma explicación sería válida para cualquier automóvil. Desafortunadamente, esta no es la respuesta correcta para un AC8 de AnyCompany, que no cuenta con un neumático de repuesto. Esto ocurre porque el modelo se entrenó con datos que contienen instrucciones acerca de cómo cambiar neumáticos de automóviles.\n",
    "\n",
    "Otro ejemplo de este problema se observa cuando se intenta hacer la misma pregunta en relación con una marca y un modelo falsos de automóvil, como un Amazon Tirana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_data = \"How can I fix a flat tire on my Amazon Tirana?\"\n",
    "body = json.dumps({\"inputText\": prompt_data, \n",
    "                   \"textGenerationConfig\": parameters})\n",
    "modelId = \"amazon.titan-text-express-v1\"  # change this to use a different version from the model provider\n",
    "accept = \"application/json\"\n",
    "contentType = \"application/json\"\n",
    "\n",
    "response = bedrock_client.invoke_model(\n",
    "    body=body, modelId=modelId, accept=accept, contentType=contentType\n",
    ")\n",
    "response_body = json.loads(response.get(\"body\").read())\n",
    "answer = response_body.get(\"results\")[0].get(\"outputText\")\n",
    "print(answer.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En función de la pregunta de la petición, el modelo no puede ofrecer una respuesta realista.\n",
    "\n",
    "Para solucionar este problema y hacer que el modelo proporcione respuestas en función de las instrucciones específicas válidas para el modelo de automóvil, puede aumentar los conocimientos del modelo al instante. Para ello, proporcione una base de conocimientos adicional como parte de la petición.\n",
    "\n",
    "Observe cómo puede aprovechar esto para mejorar la aplicación.\n",
    "\n",
    "Supongamos que lo siguiente es un extracto del manual del AC8 de AnyCompany (en realidad, no es el manual verdadero, pero trátelo como tal). Además, este documento es convenientemente corto como para ajustarse a la ventana contextual de Titan Large.\n",
    "\n",
    "```plain\n",
    "Neumáticos y su presión:\n",
    "\n",
    "Los neumáticos son de goma negra y se montan sobre las ruedas de su vehículo. Ofrecen el agarre necesario para conducir, girar y frenar. La presión y el desgaste de los neumáticos son dos factores importantes que se deben considerar, ya que pueden afectar el rendimiento y el manejo del automóvil.\n",
    "\n",
    "En dónde buscar la presión recomendada para neumáticos:\n",
    "\n",
    "Puede buscar las especificaciones sobre presión recomendada para neumáticos en la etiqueta de inflado sobre el pilar B del lado del conductor del vehículo. Como alternativa, puede consultar el manual del vehículo para obtener esta información. La presión recomendada para neumáticos puede variar en función de la velocidad y la cantidad de ocupantes o de la carga máxima del vehículo.\n",
    "\n",
    "Volver a inflar los neumáticos:\n",
    "\n",
    "Es importante verificar la presión de los neumáticos cuando estos estén fríos. Esto significa que el vehículo debe descansar durante al menos tres horas a fin de asegurarse de que los neumáticos estén a la misma temperatura que el ambiente.\n",
    "\n",
    "Para volver a inflar los neumáticos, realice lo siguiente:\n",
    "\n",
    "    Verifique la presión recomendada para neumáticos del vehículo.\n",
    "    Siga las instrucciones proporcionadas en la bomba de aire e infle los neumáticos a la presión correcta.\n",
    "    En la pantalla central del vehículo, abra la aplicación \"Car status\".\n",
    "    Vaya a la pestaña \"Tire pressure\" (Presión de los neumáticos).\n",
    "    Presione la opción \"Calibrate pressure\" (Calibrar presión) y confirme la acción.\n",
    "    Conduzca el automóvil durante unos minutos a una velocidad por encima de 30 km/h para calibrar la presión de los neumáticos.\n",
    "\n",
    "Nota: En algunos casos, es posible que sea necesario conducir durante más de 15 minutos para borrar símbolos de advertencia o mensajes relacionados con la presión de los neumáticos. Si las advertencias persisten, deje que los neumáticos se enfríen y repita los pasos anteriores.\n",
    "\n",
    "Neumático desinflado:\n",
    "\n",
    "Si uno de sus neumáticos se desinfla mientras conduce, puede sellar temporalmente la pinchadura y volver a inflar el neumático con el kit de reparación de neumáticos. Este kit, en general, se almacena por debajo del revestimiento del área de equipaje en el vehículo.\n",
    "\n",
    "Instrucciones para usar el kit de reparación de neumáticos:\n",
    "\n",
    "    Abra la puerta trasera o la caja del vehículo.\n",
    "    Levante el revestimiento del área de equipaje para acceder al kit de reparación de neumáticos.\n",
    "    Siga las instrucciones que acompañan el kit para sellar la pinchadura del neumático.\n",
    "    Después de usar el kit, asegúrese de colocarlo de nuevo en el lugar de origen.\n",
    "    Póngase en contacto con Rivesla o con el servicio apropiado para obtener asistencia en cuanto a cómo desechar y reemplazar la botella de sellador usada.\n",
    "\n",
    "Tenga en cuenta que el kit de reparación de neumáticos es una solución temporal y que se diseñó para que pueda conducir durante un máximo de 10 minutos u 8 km (lo que sea que ocurra primero) a una velocidad máxima de 80 km/h. Se recomienda cambiar el neumático pinchado o solicitar su reparación por parte de un profesional lo antes posible.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\"\"Tires and tire pressure:\n",
    "\n",
    "Tires are made of black rubber and are mounted on the wheels of your vehicle. They provide the necessary grip for driving, cornering, and braking. Two important factors to consider are tire pressure and tire wear, as they can affect the performance and handling of your car.\n",
    "\n",
    "Where to find recommended tire pressure:\n",
    "\n",
    "You can find the recommended tire pressure specifications on the inflation label located on the driver's side B-pillar of your vehicle. Alternatively, you can refer to your vehicle's manual for this information. The recommended tire pressure may vary depending on the speed and the number of occupants or maximum load in the vehicle.\n",
    "\n",
    "Reinflating the tires:\n",
    "\n",
    "When checking tire pressure, it is important to do so when the tires are cold. This means allowing the vehicle to sit for at least three hours to ensure the tires are at the same temperature as the ambient temperature.\n",
    "\n",
    "To reinflate the tires:\n",
    "\n",
    "    Check the recommended tire pressure for your vehicle.\n",
    "    Follow the instructions provided on the air pump and inflate the tire(s) to the correct pressure.\n",
    "    In the center display of your vehicle, open the \"Car status\" app.\n",
    "    Navigate to the \"Tire pressure\" tab.\n",
    "    Press the \"Calibrate pressure\" option and confirm the action.\n",
    "    Drive the car for a few minutes at a speed above 30 km/h to calibrate the tire pressure.\n",
    "\n",
    "Note: In some cases, it may be necessary to drive for more than 15 minutes to clear any warning symbols or messages related to tire pressure. If the warnings persist, allow the tires to cool down and repeat the above steps.\n",
    "\n",
    "Flat Tire:\n",
    "\n",
    "If you encounter a flat tire while driving, you can temporarily seal the puncture and reinflate the tire using a tire mobility kit. This kit is typically stored under the lining of the luggage area in your vehicle.\n",
    "\n",
    "Instructions for using the tire mobility kit:\n",
    "\n",
    "    Open the tailgate or trunk of your vehicle.\n",
    "    Lift up the lining of the luggage area to access the tire mobility kit.\n",
    "    Follow the instructions provided with the tire mobility kit to seal the puncture in the tire.\n",
    "    After using the kit, make sure to securely put it back in its original location.\n",
    "    Contact AnyCompany or an appropriate service for assistance with disposing of and replacing the used sealant bottle.\n",
    "\n",
    "Please note that the tire mobility kit is a temporary solution and is designed to allow you to drive for a maximum of 10 minutes or 8 km (whichever comes first) at a maximum speed of 80 km/h. It is advisable to replace the punctured tire or have it repaired by a professional as soon as possible.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ahora, pase el extracto completo al modelo junto con la pregunta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"How can I fix a flat tire on my AnyCompany AC8?\"\n",
    "prompt_data = f\"\"\"Answer the question based only on the information provided between ## and give step by step guide.\n",
    "#\n",
    "{context}\n",
    "#\n",
    "\n",
    "Question: {question}\n",
    "Answer:\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea 3.4: invocar el modelo mediante boto3 para generar la respuesta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = json.dumps({\"inputText\": prompt_data, \"textGenerationConfig\": parameters})\n",
    "modelId = \"amazon.titan-text-express-v1\"  # change this to use a different version from the model provider\n",
    "accept = \"application/json\"\n",
    "contentType = \"application/json\"\n",
    "\n",
    "response = bedrock_client.invoke_model(\n",
    "    body=body, modelId=modelId, accept=accept, contentType=contentType\n",
    ")\n",
    "response_body = json.loads(response.get(\"body\").read())\n",
    "answer = response_body.get(\"results\")[0].get(\"outputText\")\n",
    "print(answer.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que el modelo demora un poco en comprender el contexto y generar una respuesta pertinente, la experiencia del usuario podría ser deficiente, ya que debe esperar una respuesta durante algunos segundos.\n",
    "\n",
    "Bedrock también admite la capacidad de streaming a partir de la cual el servicio genera la salida a medida que el modelo genera los tokens. Este es un ejemplo de cómo puede implementarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_markdown,Markdown,clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response with stream\n",
    "response = bedrock_client.invoke_model_with_response_stream(body=body, modelId=modelId, accept=accept, contentType=contentType)\n",
    "stream = response.get('body')\n",
    "output = []\n",
    "i = 1\n",
    "if stream:\n",
    "    for event in stream:\n",
    "        chunk = event.get('chunk')\n",
    "        if chunk:\n",
    "            chunk_obj = json.loads(chunk.get('bytes').decode())\n",
    "            text = chunk_obj['outputText']\n",
    "            clear_output(wait=True)\n",
    "            output.append(text)\n",
    "            display_markdown(Markdown(''.join(output)))\n",
    "            i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La respuesta proporciona instrucciones resumidas y paso a paso sobre cómo cambiar los neumáticos. \n",
    "\n",
    "Aprendió cómo puede aprovechar la generación aumentada por recuperación (RAG) o el proceso de aumento para generar una respuesta seleccionada adaptada al contexto específico y a la información proporcionada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pruébelo usted mismo\n",
    "- Cambie las peticiones para que se adapten al caso práctico específico y evalúe la salida de los diferentes modelos.\n",
    "- Juegue con la longitud del token para comprender la latencia y la capacidad de respuesta del servicio.\n",
    "- Aplique diferentes principios de ingeniería de peticiones para obtener mejores salidas.\n",
    "\n",
    "### Limpieza\n",
    "\n",
    "Ha completado este cuaderno. Para ir a la siguiente parte del laboratorio, complete estos pasos:\n",
    "\n",
    "- Cierre este archivo de cuaderno y continúe con la **Tarea 4**."
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}