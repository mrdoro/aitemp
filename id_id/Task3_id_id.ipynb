{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tugas 3: Menggunakan Amazon Bedrock untuk Menjawab Pertanyaan\n",
    "\n",
    "Dalam <i>notebook</i> ini, Anda akan belajar cara menggunakan model Bedrock Titan untuk memberikan respons informasi terhadap pertanyaan dengan mengirimkan permintaan dengan konteks yang relevan penuh ke model dan mengharapkan respons balik, mengatasi tantangan dalam membuat model memberikan jawaban faktual untuk pertanyaan tanpa perlu menyiapkan dan mengindeks dokumen terlebih dahulu.\n",
    "\n",
    "<i>Notebook</i> ini mensimulasikan apa yang akan dilakukan **<i>Retrieval-Augmented Generation</i> (RAG)**, tetapi tidak benar-benar menggunakan RAG. Pendekatan ini dapat diterapkan pada dokumen pendek atau aplikasi tunggal. Pendekatan ini mungkin tidak dapat diterapkan pada jawaban pertanyaan di tingkat korporasi, karena mungkin ada dokumen korporasi berukuran besar yang tidak semuanya dapat dimasukkan ke dalam promotor yang dikirim ke model.\n",
    "\n",
    "**Menjawab Pertanyaan (QA)** adalah tugas penting yang melibatkan ekstraksi jawaban atas pertanyaan faktual yang diajukan dalam bahasa alami. Biasanya, sistem QA memproses kueri terhadap basis pengetahuan yang berisi data terstruktur atau tidak terstruktur dan menghasilkan respons dengan informasi yang akurat. Memastikan akurasi yang tinggi adalah kunci untuk mengembangkan sistem menjawab pertanyaan yang berguna, andal, dan dapat dipercaya, terutama untuk kasus penggunaan korporasi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Skenario\n",
    "\n",
    "Anda mencoba memodelkan situasi di AnyCompany yang memungkinkan Anda mengajukan pertanyaan kepada model yang menjawab guna memberikan informasi tentang penggantian ban untuk model kendaraan tertentu yang mereka produksi. Pertama, Anda menanyakan model menggunakan pendekatan “<i>zero shot</i>” untuk melihat apakah model dapat memberikan jawaban yang relevan hanya berdasarkan data pelatihannya.\n",
    "\n",
    "Namun, Anda menyadari model tersebut tampaknya \"berhalusinasi\" dengan jawaban yang lebih umum, terbukti ketika Anda mencoba model kendaraan palsu dan mendapatkan respons serupa. Hal ini menyiratkan perlunya melengkapi pelatihan model dengan manual kendaraan sebenarnya dari Example Company untuk memberikan informasi spesifik tentang ban untuk setiap model.\n",
    "\n",
    "Di lab ini, Anda akan mensimulasikan pendekatan “<i>Retrieval Augmented Generation</i>” (RAG) tanpa data eksternal. Anda memberikan kutipan manual terperinci yang menjelaskan cara mengganti ban pada kendaraan AnyCompany Model Z. Anda menguji apakah model sekarang dapat memberikan jawaban yang disesuaikan dan akurat dengan memanfaatkan konten contoh dalam konteks ini."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tugas 3.1: Pengaturan lingkungan\n",
    "\n",
    "Dalam tugas ini, Anda mengatur lingkungan Anda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#ignore warnings and create a service client by name using the default session.\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import boto3\n",
    "import botocore\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "module_path = \"..\"\n",
    "sys.path.append(os.path.abspath(module_path))\n",
    "bedrock_client = boto3.client('bedrock-runtime',region_name=os.environ.get(\"AWS_DEFAULT_REGION\", None))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tugas 3.2: Tanya Jawab dengan pengetahuan model\n",
    "Pada bagian ini kita mencoba menggunakan model yang disediakan oleh layanan Bedrock untuk menjawab pertanyaan berdasarkan pengetahuan yang diperoleh model selama fase pelatihan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dalam tugas ini, Anda menggunakan metode invoke_model () dari klien Amazon Bedrock. Parameter wajib yang diperlukan untuk menggunakan metode ini adalah modelId yang mewakili model Amazon Bedrock ARN, dan <i>body</i>, yang merupakan perintah untuk tugas Anda.\n",
    "\n",
    "Perintah <i>body</i> berubah tergantung penyedia model fondasi yang Anda pilih. Anda dapat melihat penjelasannya secara detail di bawah.\n",
    "\n",
    "```json\n",
    "{\n",
    "   modelId= model_id,\n",
    "   contentType= \"application/json\",\n",
    "   accept= \"application/json\",\n",
    "   body=body\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "Anda mencoba menggunakan model yang disediakan oleh layanan Bedrock untuk menjawab pertanyaan berdasarkan pengetahuan yang diperoleh selama fase pelatihan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_data = \"\"\"You are an helpful assistant. Answer questions in a concise way. If you are unsure about the\n",
    "answer say 'I am unsure'\n",
    "\n",
    "Question: How can I fix a flat tire on my AnyCompany AC8?\n",
    "Answer:\"\"\"\n",
    "parameters = {\n",
    "    \"maxTokenCount\":512,\n",
    "    \"stopSequences\":[],\n",
    "    \"temperature\":0,\n",
    "    \"topP\":0.9\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tugas 3.3: Menginvokasi model dengan meneruskan <i>body</i> JSON untuk menghasilkan respons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#model configuration\n",
    "body = json.dumps({\"inputText\": prompt_data, \"textGenerationConfig\": parameters})\n",
    "modelId = \"amazon.titan-text-express-v1\"  # change this to use a different version from the model provider\n",
    "accept = \"application/json\"\n",
    "contentType = \"application/json\"\n",
    "try:\n",
    "    \n",
    "    response = bedrock_client.invoke_model(\n",
    "        body=body, modelId=modelId, accept=accept, contentType=contentType\n",
    "    )\n",
    "    response_body = json.loads(response.get(\"body\").read())\n",
    "    answer = response_body.get(\"results\")[0].get(\"outputText\")\n",
    "    print(answer.strip())\n",
    "\n",
    "except botocore.exceptions.ClientError as error:\n",
    "    if  error.response['Error']['Code'] == 'AccessDeniedException':\n",
    "        print(f\"\\x1b[41m{error.response['Error']['Message']}\\\n",
    "        \\nTo troubeshoot this issue please refer to the following resources.\\\n",
    "         \\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/troubleshoot_access-denied.html\\\n",
    "         \\nhttps://docs.aws.amazon.com/bedrock/latest/userguide/security-iam.html\\x1b[0m\\n\")      \n",
    "        class StopExecution(ValueError):\n",
    "            def _render_traceback_(self):\n",
    "                pass\n",
    "        raise StopExecution        \n",
    "    else:\n",
    "        raise error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Model ini memberi Anda jawaban yang menguraikan proses penggantian ban kempes mobil, tetapi penjelasan yang sama bisa berlaku untuk mobil apa pun. Sayangnya, ini bukan jawaban yang tepat untuk AnyCompany AC8 yang tidak memiliki ban serep. Ini terjadi karena model telah dilatih dengan data yang berisi instruksi penggantian ban pada mobil.\n",
    "\n",
    "Contoh lain masalah ini dapat dilihat dengan mencoba mengajukan pertanyaan yang sama untuk merek dan model mobil palsu, misalnya Amazon Tirana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_data = \"How can I fix a flat tire on my Amazon Tirana?\"\n",
    "body = json.dumps({\"inputText\": prompt_data, \n",
    "                   \"textGenerationConfig\": parameters})\n",
    "modelId = \"amazon.titan-text-express-v1\"  # change this to use a different version from the model provider\n",
    "accept = \"application/json\"\n",
    "contentType = \"application/json\"\n",
    "\n",
    "response = bedrock_client.invoke_model(\n",
    "    body=body, modelId=modelId, accept=accept, contentType=contentType\n",
    ")\n",
    "response_body = json.loads(response.get(\"body\").read())\n",
    "answer = response_body.get(\"results\")[0].get(\"outputText\")\n",
    "print(answer.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mengingat perintah yang cepat, model tidak dapat memberikan jawaban yang realistis.\n",
    "\n",
    "Untuk memperbaiki masalah ini dan meminta model memberikan jawaban berdasarkan instruksi khusus yang berlaku untuk model mobil Anda, Anda dapat menambah pengetahuan model secara langsung dengan memberikan basis pengetahuan tambahan sebagai bagian dari perintah.\n",
    "\n",
    "Mari kita lihat bagaimana Anda dapat menggunakan ini untuk meningkatkan aplikasi.\n",
    "\n",
    "Asumsikan ini adalah kutipan buku manual AnyCompany AC8 (sebenarnya ini bukan buku manual sebenarnya, tetapi anggap saja begitu). Dokumen ini juga cukup singkat sehingga sesuai dengan jendela konteks Titan Large.\n",
    "\n",
    "```plain\n",
    "Ban dan Tekanan Ban:\n",
    "\n",
    "Ban terbuat dari karet berwarna hitam dan dipasang pada roda kendaraan Anda. Ban memberikan cengkeraman yang diperlukan untuk mengemudi, berbelok, dan mengerem. Dua faktor penting yang perlu diperhatikan adalah tekanan ban dan keausan ban, karena dapat memengaruhi kinerja dan penanganan mobil Anda.\n",
    "\n",
    "Tempat untuk Menemukan Tekanan Ban yang Direkomendasikan:\n",
    "\n",
    "Anda dapat menemukan spesifikasi tekanan ban yang direkomendasikan pada label pemompaan yang ada di pilar B sisi pengemudi kendaraan. Sebagai alternatif, Anda juga dapat melihat manual kendaraan Anda untuk informasi ini. Tekanan ban yang disarankan dapat bervariasi, tergantung pada kecepatan dan jumlah penumpang atau muatan maksimum di dalam kendaraan.\n",
    "\n",
    "Mengisi Ulang Angin Ban:\n",
    "\n",
    "Saat memeriksa tekanan ban, penting untuk melakukannya saat ban dalam keadaan dingin. Itu berarti mendiamkan kendaraan setidaknya selama tiga jam untuk memastikan suhu ban sama dengan suhu sekitar.\n",
    "\n",
    "Cara mengisi ulang angin ban:\n",
    "\n",
    "    Periksa tekanan ban yang direkomendasikan untuk kendaraan Anda.\n",
    "    Ikuti instruksi yang diberikan pada pompa udara dan pompa ban hingga mencapai tekanan yang benar.\n",
    "    Di tampilan tengah kendaraan Anda, buka aplikasi \"Status mobil\".\n",
    "    Buka tab “Tekanan ban”.\n",
    "    Tekan opsi “Kalibrasi tekanan” dan konfirmasi tindakan.\n",
    "    Kendarai mobil selama beberapa menit dengan kecepatan di atas 30 km/jam untuk mengalibrasi tekanan ban.\n",
    "\n",
    "Catatan: Dalam beberapa kasus, mungkin Anda perlu berkendara lebih dari 15 menit untuk menghapus simbol atau pesan peringatan apa pun yang terkait dengan tekanan ban. Jika peringatan terus muncul, dinginkan ban dan ulangi langkah di atas.\n",
    "\n",
    "Ban Kempis:\n",
    "\n",
    "Jika ban kempis saat mengemudi, Anda dapat menutup sementara sobekan pada ban tersebut dan mengisi kembali ban menggunakan alat mobilitas ban. Alat ini biasanya disimpan di bawah lapisan area bagasi kendaraan Anda.\n",
    "\n",
    "Instruksi Penggunaan Alat Mobilitas Ban:\n",
    "\n",
    "    Buka pintu belakang atau bagasi kendaraan Anda.\n",
    "    Angkat lapisan area bagasi untuk mengakses alat mobilitas ban.\n",
    "    Ikuti instruksi yang diberikan bersama alat mobilitas ban untuk menambal sobekan pada ban.\n",
    "    Setelah menggunakan alat, pastikan untuk mengembalikannya dengan aman di lokasi asalnya.\n",
    "    Hubungi Rivesla atau layanan yang sesuai untuk mendapatkan bantuan dalam membuang dan mengganti botol las ban bekas.\n",
    "\n",
    "Harap dicatat bahwa alat mobilitas ban adalah solusi sementara dan dirancang untuk memungkinkan Anda berkendara maksimal 10 menit atau 8 km (mana saja yang lebih dulu) dengan kecepatan maksimum 80 km/jam. Disarankan untuk mengganti ban yang bocor atau membawanya untuk diperbaiki tenaga profesional sesegera mungkin.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\"\"Tires and tire pressure:\n",
    "\n",
    "Tires are made of black rubber and are mounted on the wheels of your vehicle. They provide the necessary grip for driving, cornering, and braking. Two important factors to consider are tire pressure and tire wear, as they can affect the performance and handling of your car.\n",
    "\n",
    "Where to find recommended tire pressure:\n",
    "\n",
    "You can find the recommended tire pressure specifications on the inflation label located on the driver's side B-pillar of your vehicle. Alternatively, you can refer to your vehicle's manual for this information. The recommended tire pressure may vary depending on the speed and the number of occupants or maximum load in the vehicle.\n",
    "\n",
    "Reinflating the tires:\n",
    "\n",
    "When checking tire pressure, it is important to do so when the tires are cold. This means allowing the vehicle to sit for at least three hours to ensure the tires are at the same temperature as the ambient temperature.\n",
    "\n",
    "To reinflate the tires:\n",
    "\n",
    "    Check the recommended tire pressure for your vehicle.\n",
    "    Follow the instructions provided on the air pump and inflate the tire(s) to the correct pressure.\n",
    "    In the center display of your vehicle, open the \"Car status\" app.\n",
    "    Navigate to the \"Tire pressure\" tab.\n",
    "    Press the \"Calibrate pressure\" option and confirm the action.\n",
    "    Drive the car for a few minutes at a speed above 30 km/h to calibrate the tire pressure.\n",
    "\n",
    "Note: In some cases, it may be necessary to drive for more than 15 minutes to clear any warning symbols or messages related to tire pressure. If the warnings persist, allow the tires to cool down and repeat the above steps.\n",
    "\n",
    "Flat Tire:\n",
    "\n",
    "If you encounter a flat tire while driving, you can temporarily seal the puncture and reinflate the tire using a tire mobility kit. This kit is typically stored under the lining of the luggage area in your vehicle.\n",
    "\n",
    "Instructions for using the tire mobility kit:\n",
    "\n",
    "    Open the tailgate or trunk of your vehicle.\n",
    "    Lift up the lining of the luggage area to access the tire mobility kit.\n",
    "    Follow the instructions provided with the tire mobility kit to seal the puncture in the tire.\n",
    "    After using the kit, make sure to securely put it back in its original location.\n",
    "    Contact AnyCompany or an appropriate service for assistance with disposing of and replacing the used sealant bottle.\n",
    "\n",
    "Please note that the tire mobility kit is a temporary solution and is designed to allow you to drive for a maximum of 10 minutes or 8 km (whichever comes first) at a maximum speed of 80 km/h. It is advisable to replace the punctured tire or have it repaired by a professional as soon as possible.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sekarang, berikan seluruh kutipannya ke model bersama dengan pertanyaan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"How can I fix a flat tire on my AnyCompany AC8?\"\n",
    "prompt_data = f\"\"\"Answer the question based only on the information provided between ## and give step by step guide.\n",
    "#\n",
    "{context}\n",
    "#\n",
    "\n",
    "Question: {question}\n",
    "Answer:\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tugas 3.4: Menginvokasi model melalui boto3 untuk menghasilkan respons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = json.dumps({\"inputText\": prompt_data, \"textGenerationConfig\": parameters})\n",
    "modelId = \"amazon.titan-text-express-v1\"  # change this to use a different version from the model provider\n",
    "accept = \"application/json\"\n",
    "contentType = \"application/json\"\n",
    "\n",
    "response = bedrock_client.invoke_model(\n",
    "    body=body, modelId=modelId, accept=accept, contentType=contentType\n",
    ")\n",
    "response_body = json.loads(response.get(\"body\").read())\n",
    "answer = response_body.get(\"results\")[0].get(\"outputText\")\n",
    "print(answer.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Karena model membutuhkan waktu cukup lama untuk memahami konteks dan menghasilkan jawaban yang relevan untuk Anda, hal ini mungkin menyebabkan pengalaman buruk bagi pengguna karena mereka harus menunggu respons selama beberapa detik.\n",
    "\n",
    "Bedrock juga mendukung kemampuan <i>streaming</i> tempat layanan menghasilkan <i>output</i> saat model menghasilkan token. Berikut contoh cara Anda bisa melakukannya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_markdown,Markdown,clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response with stream\n",
    "response = bedrock_client.invoke_model_with_response_stream(body=body, modelId=modelId, accept=accept, contentType=contentType)\n",
    "stream = response.get('body')\n",
    "output = []\n",
    "i = 1\n",
    "if stream:\n",
    "    for event in stream:\n",
    "        chunk = event.get('chunk')\n",
    "        if chunk:\n",
    "            chunk_obj = json.loads(chunk.get('bytes').decode())\n",
    "            text = chunk_obj['outputText']\n",
    "            clear_output(wait=True)\n",
    "            output.append(text)\n",
    "            display_markdown(Markdown(''.join(output)))\n",
    "            i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Responsnya memberikan ringkasan petunjuk langkah demi langkah tentang cara mengganti ban. \n",
    "\n",
    "Anda sekarang telah mempelajari cara memanfaatkan <i>Retrieval Augmented Generation</i> (RAG) atau proses Augmentasi untuk menghasilkan respons yang dikurasi dan disesuaikan dengan konteks dan informasi spesifik yang diberikan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cobalah sendiri\n",
    "- Ubah perintah untuk kasus penggunaan spesifik Anda dan evaluasi <i>output</i> model yang berbeda.\n",
    "- Atur panjang token untuk memahami latensi dan responsivitas layanan.\n",
    "- Terapkan berbagai prinsip rekayasa perintah untuk mendapatkan <i>output</i> yang lebih baik.\n",
    "\n",
    "### Pembersihan\n",
    "\n",
    "Anda telah menyelesaikan <i>notebook</i> ini. Untuk pindah ke bagian lab berikutnya, lakukan hal berikut:\n",
    "\n",
    "- Tutup <i>file notebook</i> ini dan lanjutkan dengan **Tugas 4**."
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}