{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarefa 3: Usar o Amazon Bedrock para responder perguntas\n",
    "\n",
    "Neste caderno, você aprenderá a usar o modelo Titan do Bedrock para fornecer respostas informativas a consultas enviando a solicitação com todo o contexto relevante ao modelo e esperando a resposta, enfrentando o desafio de fazer com que o modelo retorne respostas factuais para perguntas sem precisar preparar e indexar documentos previamente.\n",
    "\n",
    "Este caderno simula o que a **Geração aumentada de recuperação (RAG)** faria, mas sem usar RAG de fato. Essa abordagem funciona para documentos curtos ou aplicações singleton. Sua escala pode não ser adequada no caso de uso de responder perguntas em nível empresarial, visto que nem todos os documentos grandes necessários cabem no prompt enviado para o modelo.\n",
    "\n",
    "**Responder perguntas (QA)** é uma tarefa importante que envolve extrair respostas para consultas factuais feitas em uma linguagem natural. Normalmente, um sistema de QA processa uma consulta em uma base de conhecimento que contém dados estruturados ou não estruturados e gera uma resposta com informações precisas. Garantir um alto nível de acurácia é essencial para desenvolver um sistema de resposta a perguntas útil e confiável, principalmente para casos de uso empresariais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Cenário\n",
    "\n",
    "Você tenta modelar uma situação na AnyCompany em que pede para que um modelo de respostas a perguntas dê informações sobre a troca de pneus para um modelo de veículo específico que ela fabrica. Primeiro, você consulta o modelo usando uma abordagem \"zero-shot\" para ver se ele pode dar respostas relevantes com base apenas nos dados de treinamento dele.\n",
    "\n",
    "No entanto, você percebe que o modelo parece estar \"alucinando\" respostas mais genéricas, conforme evidenciado quando você testa um modelo de veículo falso e obtém respostas semelhantes. Isso sugere a necessidade de aumentar o treinamento do modelo com os manuais de veículos reais da Example Company para dar detalhes sobre os pneus de cada modelo.\n",
    "\n",
    "Neste laboratório, você simula essa abordagem de \"geração aumentada de recuperação\" (RAG) sem dados externos. Você fornece um trecho detalhado do manual explicando como trocar os pneus no veículo Modelo Z da AnyCompany. Você testa se o modelo agora pode fornecer uma resposta personalizada e precisa usando esse exemplo de conteúdo contextualizado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarefa 3.1: Configurar o ambiente\n",
    "\n",
    "Nesta tarefa, você vai configurar o ambiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#ignore warnings and create a service client by name using the default session.\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import boto3\n",
    "import botocore\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "module_path = \"..\"\n",
    "sys.path.append(os.path.abspath(module_path))\n",
    "bedrock_client = boto3.client('bedrock-runtime',region_name=os.environ.get(\"AWS_DEFAULT_REGION\", None))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarefa 3.2: Perguntas e respostas com o conhecimento do modelo\n",
    "Nesta seção, tentamos usar modelos oferecidos pelo serviço Bedrock para responder a perguntas com base no conhecimento que eles adquiriram durante a fase de treinamento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nessa tarefa, você usa o método invoke_model () do cliente do Amazon Bedrock. Os parâmetros obrigatórios para usar esse método são: \"modelId\", que representa o ARN do modelo do Amazon Bedrock; além de \"body\", que é o prompt de sua tarefa.\n",
    "\n",
    "O formato do texto do prompt muda conforme o provedor do modelo de base selecionado. Você verá isso em detalhes abaixo.\n",
    "\n",
    "```json\n",
    "{\n",
    "   modelId= model_id,\n",
    "   contentType= \"application/json\",\n",
    "   accept= \"application/json\",\n",
    "   body=body\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "Você tenta usar modelos fornecidos pelo serviço Bedrock para responder perguntas com base no conhecimento adquirido durante a fase de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_data = \"\"\"You are an helpful assistant. Answer questions in a concise way. If you are unsure about the\n",
    "answer say 'I am unsure'\n",
    "\n",
    "Question: How can I fix a flat tire on my AnyCompany AC8?\n",
    "Answer:\"\"\"\n",
    "parameters = {\n",
    "    \"maxTokenCount\":512,\n",
    "    \"stopSequences\":[],\n",
    "    \"temperature\":0,\n",
    "    \"topP\":0.9\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarefa 3.3: Invocar o modelo ao usar o formato de texto JSON para gerar a resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#model configuration\n",
    "body = json.dumps({\"inputText\": prompt_data, \"textGenerationConfig\": parameters})\n",
    "modelId = \"amazon.titan-text-express-v1\"  # change this to use a different version from the model provider\n",
    "accept = \"application/json\"\n",
    "contentType = \"application/json\"\n",
    "try:\n",
    "    \n",
    "    response = bedrock_client.invoke_model(\n",
    "        body=body, modelId=modelId, accept=accept, contentType=contentType\n",
    "    )\n",
    "    response_body = json.loads(response.get(\"body\").read())\n",
    "    answer = response_body.get(\"results\")[0].get(\"outputText\")\n",
    "    print(answer.strip())\n",
    "\n",
    "except botocore.exceptions.ClientError as error:\n",
    "    if  error.response['Error']['Code'] == 'AccessDeniedException':\n",
    "        print(f\"\\x1b[41m{error.response['Error']['Message']}\\\n",
    "        \\nTo troubeshoot this issue please refer to the following resources.\\\n",
    "         \\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/troubleshoot_access-denied.html\\\n",
    "         \\nhttps://docs.aws.amazon.com/bedrock/latest/userguide/security-iam.html\\x1b[0m\\n\")      \n",
    "        class StopExecution(ValueError):\n",
    "            def _render_traceback_(self):\n",
    "                pass\n",
    "        raise StopExecution        \n",
    "    else:\n",
    "        raise error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "O modelo fornece uma resposta descrevendo o processo de troca do pneu furado do carro, mas a mesma explicação pode ser válida para qualquer carro. Infelizmente, essa não é a resposta correta para um AnyCompany AC8, que não tem estepe. Isso ocorre porque o modelo foi treinado com dados que contêm instruções sobre a troca de pneus em carros.\n",
    "\n",
    "Outro exemplo desse problema pode ser encontrado ao tentar fazer a mesma pergunta usando uma marca e modelo de carro totalmente falsos, como Amazon Tirana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_data = \"How can I fix a flat tire on my Amazon Tirana?\"\n",
    "body = json.dumps({\"inputText\": prompt_data, \n",
    "                   \"textGenerationConfig\": parameters})\n",
    "modelId = \"amazon.titan-text-express-v1\"  # change this to use a different version from the model provider\n",
    "accept = \"application/json\"\n",
    "contentType = \"application/json\"\n",
    "\n",
    "response = bedrock_client.invoke_model(\n",
    "    body=body, modelId=modelId, accept=accept, contentType=contentType\n",
    ")\n",
    "response_body = json.loads(response.get(\"body\").read())\n",
    "answer = response_body.get(\"results\")[0].get(\"outputText\")\n",
    "print(answer.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considerando a pergunta do prompt, o modelo é incapaz de fornecer uma resposta realista.\n",
    "\n",
    "Para resolver esse problema e fazer com que o modelo dê respostas com base nas instruções específicas válidas para o modelo do seu carro, você pode aumentar imediatamente o conhecimento do modelo fornecendo uma base de conhecimento adicional como parte do prompt.\n",
    "\n",
    "Vamos ver como você pode usar isso para melhorar sua aplicação.\n",
    "\n",
    "Suponha que o trecho a seguir seja do manual do AnyCompany AC8 (na realidade, não é o manual real, mas trate-o como tal). Esse documento também é convenientemente curto o bastante para caber inteiramente na janela de contexto do Titan Large.\n",
    "\n",
    "```plain\n",
    "Pneus e pressão dos pneus:\n",
    "\n",
    "Os pneus são feitos de borracha preta e são montados nas rodas do seu veículo. Eles oferecem a aderência necessária para dirigir, manobrar e frear. Dois fatores importantes a considerar são a pressão e o desgaste dos pneus, pois eles podem afetar o desempenho e dirigibilidade do carro.\n",
    "\n",
    "Onde encontrar a pressão recomendada para os pneus:\n",
    "\n",
    "Você pode encontrar as especificações de pressão recomendada para o pneu na etiqueta de calibragem localizada na coluna B do lado do motorista no veículo. Como alternativa, você pode consultar o manual do veículo para encontrar esta informação. A pressão recomendada para o pneu pode variar dependendo da velocidade e do número de ocupantes ou carga máxima dentro do veículo.\n",
    "\n",
    "Recalibragem dos pneus:\n",
    "\n",
    "É importante verificar a pressão dos pneus quando eles estiverem frios. Para isso, o veículo deve permanecer parado por pelo menos três horas. Isso garante que a temperatura dos pneus se iguale à ambiente.\n",
    "\n",
    "Para recalibrar os pneus:\n",
    "\n",
    "    Verifique a pressão recomendada para os pneus do seu veículo.\n",
    "    Siga as instruções fornecidas na bomba pneumática e calibre um ou mais pneus com a pressão correta.\n",
    "    No painel central do veículo, abra a aplicação “Status do carro”.\n",
    "    Navegue até a aba “Pressão dos pneus”.\n",
    "    Pressione a opção “Calibrar pressão” e confirme a ação.\n",
    "    Dirija o carro por alguns minutos a uma velocidade acima de 30 km/h para calibrar a pressão dos pneus.\n",
    "\n",
    "Observação: em alguns casos, pode ser necessário dirigir por mais de 15 minutos para apagar qualquer símbolo ou mensagem de aviso relacionado à pressão do pneu. Se os avisos persistirem, deixe os pneus esfriarem e repita as etapas acima.\n",
    "\n",
    "Pneu furado:\n",
    "\n",
    "Se algum pneu furar enquanto você dirige, é possível vedar o furo de forma temporária e recalibrar o pneu usando um kit de reparo. Normalmente, esse kit é armazenado abaixo do forro no porta-malas do veículo.\n",
    "\n",
    "Instruções para utilizar o kit de reparo para pneu:\n",
    "\n",
    "    Abra a tampa traseira ou o porta-malas do veículo.\n",
    "    Levante o forro do porta-malas para acessar o kit de reparo para pneu.\n",
    "    Siga as instruções descritas no kit de reparo para vedar o furo no pneu.\n",
    "    Após usar o kit, coloque-o de volta no lugar original de forma segura.\n",
    "    Entre em contato com a Rivesla ou com um serviço apropriado para receber ajuda no descarte e substituição da garrafa de vedante usada.\n",
    "\n",
    "Lembre-se de que p kit de reparo para pneu é uma solução temporária. Ele permite que você dirija por no máximo 10 minutos ou 8 km (o que acontecer primeiro) a uma velocidade máxima de 80 km/h. Aconselhamos que você troque o pneu furado ou encontre um profissional para repará-lo o mais rápido possível.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\"\"Tires and tire pressure:\n",
    "\n",
    "Tires are made of black rubber and are mounted on the wheels of your vehicle. They provide the necessary grip for driving, cornering, and braking. Two important factors to consider are tire pressure and tire wear, as they can affect the performance and handling of your car.\n",
    "\n",
    "Where to find recommended tire pressure:\n",
    "\n",
    "You can find the recommended tire pressure specifications on the inflation label located on the driver's side B-pillar of your vehicle. Alternatively, you can refer to your vehicle's manual for this information. The recommended tire pressure may vary depending on the speed and the number of occupants or maximum load in the vehicle.\n",
    "\n",
    "Reinflating the tires:\n",
    "\n",
    "When checking tire pressure, it is important to do so when the tires are cold. This means allowing the vehicle to sit for at least three hours to ensure the tires are at the same temperature as the ambient temperature.\n",
    "\n",
    "To reinflate the tires:\n",
    "\n",
    "    Check the recommended tire pressure for your vehicle.\n",
    "    Follow the instructions provided on the air pump and inflate the tire(s) to the correct pressure.\n",
    "    In the center display of your vehicle, open the \"Car status\" app.\n",
    "    Navigate to the \"Tire pressure\" tab.\n",
    "    Press the \"Calibrate pressure\" option and confirm the action.\n",
    "    Drive the car for a few minutes at a speed above 30 km/h to calibrate the tire pressure.\n",
    "\n",
    "Note: In some cases, it may be necessary to drive for more than 15 minutes to clear any warning symbols or messages related to tire pressure. If the warnings persist, allow the tires to cool down and repeat the above steps.\n",
    "\n",
    "Flat Tire:\n",
    "\n",
    "If you encounter a flat tire while driving, you can temporarily seal the puncture and reinflate the tire using a tire mobility kit. This kit is typically stored under the lining of the luggage area in your vehicle.\n",
    "\n",
    "Instructions for using the tire mobility kit:\n",
    "\n",
    "    Open the tailgate or trunk of your vehicle.\n",
    "    Lift up the lining of the luggage area to access the tire mobility kit.\n",
    "    Follow the instructions provided with the tire mobility kit to seal the puncture in the tire.\n",
    "    After using the kit, make sure to securely put it back in its original location.\n",
    "    Contact AnyCompany or an appropriate service for assistance with disposing of and replacing the used sealant bottle.\n",
    "\n",
    "Please note that the tire mobility kit is a temporary solution and is designed to allow you to drive for a maximum of 10 minutes or 8 km (whichever comes first) at a maximum speed of 80 km/h. It is advisable to replace the punctured tire or have it repaired by a professional as soon as possible.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Agora, transmita o trecho inteiro para o modelo com a pergunta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"How can I fix a flat tire on my AnyCompany AC8?\"\n",
    "prompt_data = f\"\"\"Answer the question based only on the information provided between ## and give step by step guide.\n",
    "#\n",
    "{context}\n",
    "#\n",
    "\n",
    "Question: {question}\n",
    "Answer:\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarefa 3.4: Invocar o modelo via boto3 para gerar a resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = json.dumps({\"inputText\": prompt_data, \"textGenerationConfig\": parameters})\n",
    "modelId = \"amazon.titan-text-express-v1\"  # change this to use a different version from the model provider\n",
    "accept = \"application/json\"\n",
    "contentType = \"application/json\"\n",
    "\n",
    "response = bedrock_client.invoke_model(\n",
    "    body=body, modelId=modelId, accept=accept, contentType=contentType\n",
    ")\n",
    "response_body = json.loads(response.get(\"body\").read())\n",
    "answer = response_body.get(\"results\")[0].get(\"outputText\")\n",
    "print(answer.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como o modelo demora um pouco para compreender o contexto e gerar uma resposta relevante para você, isso pode resultar em uma experiência do usuário ruim, pois é necessário aguardar uma resposta por alguns segundos.\n",
    "\n",
    "O Bedrock também é compatível com o recurso de transmissão em que o serviço gera saída conforme o modelo gera tokens. Aqui, é possível ver um exemplo de como você pode implementar isso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_markdown,Markdown,clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response with stream\n",
    "response = bedrock_client.invoke_model_with_response_stream(body=body, modelId=modelId, accept=accept, contentType=contentType)\n",
    "stream = response.get('body')\n",
    "output = []\n",
    "i = 1\n",
    "if stream:\n",
    "    for event in stream:\n",
    "        chunk = event.get('chunk')\n",
    "        if chunk:\n",
    "            chunk_obj = json.loads(chunk.get('bytes').decode())\n",
    "            text = chunk_obj['outputText']\n",
    "            clear_output(wait=True)\n",
    "            output.append(text)\n",
    "            display_markdown(Markdown(''.join(output)))\n",
    "            i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A resposta fornece instruções passo a passo resumidas sobre como trocar os pneus. \n",
    "\n",
    "Você aprendeu a usar a geração aumentada de recuperação (RAG) ou o processo de aumento para gerar uma resposta com curadoria adaptada ao contexto específico e às informações fornecidas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimente você mesmo\n",
    "- Altere os prompts para seu caso de uso específico e avalie o resultado de diferentes modelos.\n",
    "- Teste o comprimento do token para entender a latência e a responsividade do serviço.\n",
    "- Aplique diferentes princípios de engenharia de prompts para gerar resultados melhores.\n",
    "\n",
    "### Limpeza\n",
    "\n",
    "Você concluiu este caderno. Passe para a próxima parte do laboratório da seguinte forma:\n",
    "\n",
    "- Feche este arquivo de caderno e continue com a **Tarefa 4**."
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}