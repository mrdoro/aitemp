{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adba6786",
   "metadata": {},
   "source": [
    "# 태스크 6: Langchain 에이전트와 Bedrock 모델 통합\n",
    "\n",
    "이 노트북에서는 에이전트가 사용할 수 있는 도구를 사용하여 작업 순서를 결정하고, 이를 구현하는 계획 및 실행 에이전트를 사용하는 방법을 알아보겠습니다. \n",
    "\n",
    "특정 애플리케이션은 사용자의 질문에 답변하기 위해 언어 모델과 다양한 유틸리티에 대한 적응 가능한 호출 순서를 요구합니다. LangChain 에이전트 인터페이스는 유연하며, 외부 도구와 LLM의 추론을 통합할 수 있습니다. 에이전트는 사용자 입력에 따라 사용할 도구를 선택할 수 있습니다. 에이전트는 여러 도구를 사용할 수 있으며 한 도구의 출력을 다음 도구의 입력으로 활용할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47af1034",
   "metadata": {},
   "source": [
    "## 태스크 6.1: 환경 설정\n",
    "\n",
    "이 태스크에서는 환경을 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bd8701-e959-401b-b066-2ad2acea9542",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a service client by name using the default session.\n",
    "import math\n",
    "import numexpr\n",
    "import json\n",
    "import datetime\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import boto3\n",
    "\n",
    "module_path = \"..\"\n",
    "sys.path.append(os.path.abspath(module_path))\n",
    "bedrock_client = boto3.client('bedrock-runtime',region_name=os.environ.get(\"AWS_DEFAULT_REGION\", None))\n",
    "model_id = \"anthropic.claude-3-sonnet-20240229-v1:0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38be8de",
   "metadata": {},
   "source": [
    "다음으로, Amazon Bedrock에서 호스팅되는 대화형 AI 모델과 상호 작용할 수 있는 LangChain의 ChatBedrock 클래스 인스턴스를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a1ddab-343c-46a2-b2e9-d05550981474",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an instance of the ChatBedrock\n",
    "from langchain_aws import ChatBedrock\n",
    "\n",
    "chat_model=ChatBedrock(\n",
    "    model_id=model_id , \n",
    "    client=bedrock_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4063c43-3120-44a1-b126-a288696179a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#invoke model\n",
    "chat_model.invoke(\"what is AWS? Answer in a single senetence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef24bea",
   "metadata": {},
   "source": [
    "## 태스크 6.2: Synergizing Reasoning and Acting in Language Models 프레임워크\n",
    "\n",
    "이 태스크에서 ReAct 프레임워크는 대규모 언어 모델이 외부 도구와 상호 작용하여 보다 더 정확하고 사실에 기반한 응답을 제공하는 추가 정보를 얻을 수 있게 합니다.\n",
    "\n",
    "대규모 언어 모델은 추론에 대한 설명과 작업별 응답을 교대로 생성할 수 있습니다.\n",
    "\n",
    "추론 설명을 생성하면 모델이 실행 계획을 추론, 모니터링 및 수정할 수 있고, 예상치 못한 시나리오도 처리할 수도 있습니다. 실행 단계에서 모델은 지식 기반 또는 환경과 같은 외부 소스와 인터페이스를 통해 정보를 획득할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e54d64-a766-4303-9aff-a73f0a87c8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1defc7f-4475-4071-9ab3-ff5806d068d1",
   "metadata": {},
   "source": [
    "다음 셀에서는 Langchain 프레임워크 내에서 도구 역할을 하는 `calculator` 함수를 정의합니다. 이 도구는 언어 모델이 Python의 numexpr 라이브러리를 사용해 주어진 식을 평가하여 수학적 계산을 수행할 수 있게 합니다. 이 도구는 식이 유효하지 않은 경우를 처리하도록 설계되었습니다. 이 경우, 이 도구는 계산에 대한 접근 방식 재고하도록 모델에 요청합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6155c82-eb40-4eff-b5d5-d9fec4905278",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_product_price(query:str):\n",
    "    \"Useful when you need to lookup product price\"\n",
    "    import csv\n",
    "    prices = {}\n",
    "    try:\n",
    "        file=open('sales.csv', 'r')\n",
    "    except Exception as e:\n",
    "        return (\"Unable to look up the price for \" + query)\n",
    "    reader = csv.DictReader(file)\n",
    "    for row in reader:\n",
    "        prices[row['product_id']] = row['price']\n",
    "    file.close()\n",
    "    qstr=query.split(\"\\n\")[0].strip()\n",
    "    try:\n",
    "            return (\"Price of product \"+qstr+\" is \"+prices.get(qstr)+\"\\n\")\n",
    "    except:\n",
    "            return (\"Price for product \"+qstr+\" is not avilable\"+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ce2b82-438c-4b13-a941-74c79d6526c3",
   "metadata": {},
   "source": [
    "다음 셀에서는 Langchain 프레임워크 내에서 도구 역할을 하는 `calculator` 함수를 정의합니다. 이 도구를 사용하면 언어 모델에서 Python의 numexpr 라이브러리를 통해 주어진 표현식을 평가하여 수학적 계산을 수행할 수 있습니다. 표현식이 유효하지 않은 사례가 처리되도록 도구가 설계되었습니다. 해당 사례에서는 계산에 대한 접근 방식 재고를 모델에 요청합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c3256c-0806-4a19-ad42-4a2153f9ea9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def calculator(expression: str) -> str:\n",
    "    \"\"\"Use this tool to solve a math problems that involve a single line mathematical expression.\n",
    "    Use math notation and not words. \n",
    "    Examples:\n",
    "        \"5*4\" for \"5 times 4\"\n",
    "        \"5/4\" for \"5 divided by 4\"\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return str(\n",
    "            numexpr.evaluate(\n",
    "            expression.strip(),\n",
    "            global_dict={},  \n",
    "            local_dict={} # add math constants, if needed\n",
    "            )\n",
    "        )\n",
    "    except Exception as e:\n",
    "        return \"Rethink your approach to this calculation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad97004-e7b8-4479-b966-2b276f8e55ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [get_product_price, calculator]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5a0ac1-d256-4188-b6b7-22a5f6960d34",
   "metadata": {},
   "source": [
    "다음 셀에서는 helper 함수를 실행하여 추적 출력을 파일에 인쇄합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5321facb-cfc9-4e86-a669-db6dbdf116b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage, ToolMessage\n",
    "def output_trace(element:str, trace, node=True):\n",
    "    global trace_handle\n",
    "    if trace_enabled:\n",
    "        print(datetime.datetime.now(),file=trace_handle)\n",
    "        print((\"Node: \" if node else \"Edge: \")+ element, file=trace_handle)\n",
    "        if element == \"ask_model_to_reason (entry)\":\n",
    "            for single_trace in trace:\n",
    "                print(single_trace, file=trace_handle)\n",
    "        else:\n",
    "            print(trace, file=trace_handle)\n",
    "        print('----', file=trace_handle)\n",
    "        \n",
    "def consolidate_tool_messages(message):\n",
    "    tool_messages=[]\n",
    "    for msg in message:\n",
    "        if isinstance(msg, ToolMessage):\n",
    "            tool_messages.append(msg)\n",
    "    return tool_messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d320f3b2",
   "metadata": {},
   "source": [
    "## 태스크 6.3: 에이전트 그래프 구축\n",
    "\n",
    "이 태스크에서는 외부 도구와 상호 작용할 수 있는 대화형 AI 시스템용 에이전트 그래프를 생성하게 됩니다. 에이전트 그래프는 도구와의 대화 및 상호 작용 흐름이 정의되는 상태 머신입니다.\n",
    "\n",
    "다음 셀에서는 입력에 따라 상태를 업데이트하는 관련 함수가 있는 노드를 정의합니다. 그래프가 한 노드에서 다음 노드로 전환되는 가장자리를 사용하여 노드를 연결합니다. 조건부 에지를 통합하여 특정 조건에 따라 그래프를 다른 노드로 라우팅합니다. 마지막으로 에이전트 그래프를 컴파일하여 정의된 대로 전환 및 상태 업데이트를 처리하여 실행을 준비합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3001b5-f508-4e41-8c78-35d6e5455ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from langgraph.graph import StateGraph, MessagesState\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "# ToolNode is a prebuilt component that runs the tool and appends the tool result to the messages \n",
    "tool_node = ToolNode(tools)\n",
    "\n",
    "# let the model know the tools it can access\n",
    "model_with_tools = chat_model.bind_tools(tools)\n",
    "    \n",
    "# The following function acts as the conditional edge in the graph.\n",
    "# The next node could be the tools node or the end of the chain.\n",
    "def next_step(state: MessagesState) -> Literal[\"tools\", \"__end__\"]:\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    if last_message.tool_calls:\n",
    "        output_trace(\"next_step: Proceed to tools\",last_message, node=False)\n",
    "        return \"tools\"\n",
    "    output_trace(\"next_step: Proceed to end\",last_message, node=False)\n",
    "    return \"__end__\"\n",
    "\n",
    "#.The following node function invokes the model that has information about the available tools\n",
    "def ask_model_to_reason(state: MessagesState):\n",
    "    messages = state[\"messages\"]\n",
    "    output_trace(\"ask_model_to_reason (entry)\", consolidate_tool_messages(messages))\n",
    "    try:\n",
    "        response = model_with_tools.invoke(messages)\n",
    "    except Exception as e:\n",
    "        output_trace(\"ask_model_to_reason\", messages)\n",
    "        output_trace(\"ask_model_to_reason\", \"Exception: \"+str(e))\n",
    "        return {\"messages\": [messages.append(\"Unable to invoke the model\")]}\n",
    "    output_trace(\"ask_model_to_reason (exit)\", response)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "agent_graph = StateGraph(MessagesState)\n",
    "\n",
    "# Describe the nodes. \n",
    "# The first argument is the unique node name, and the second argument is the \n",
    "# function or object that will be called when the node is reached\n",
    "agent_graph.add_node(\"agent\", ask_model_to_reason)\n",
    "agent_graph.add_node(\"tools\", tool_node)\n",
    "\n",
    "# Connect the entry node to the agent for the graph to start running\n",
    "agent_graph.add_edge(\"__start__\", \"agent\")\n",
    "\n",
    "# Once the graph transitions to the tools node, the graph will transition to the agent node\n",
    "agent_graph.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "# The transition out of the agent node is conditional. \n",
    "# If the output from ask_model_to_reason function included a call to the tools, call the tool; \n",
    "# otherwise end the chain \n",
    "agent_graph.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    next_step,\n",
    ")\n",
    "\n",
    "# Compile the graph definition so that it can run\n",
    "\n",
    "react_agent = agent_graph.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869ba496-f4e8-459c-a8e0-1add96724640",
   "metadata": {},
   "source": [
    "다음으로 컴파일된 그래프를 시각화합니다. 점선으로 표시된 것처럼 에이전트 노드에서 조건부로 전환되는 것을 관찰합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fe11dc-4a20-4f82-82a0-7a2b21261ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(react_agent.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd12e190-6682-422b-a7e7-902baeab368f",
   "metadata": {},
   "source": [
    "다음 셀에서는 helper 함수를 실행하여 그래프 출력을 인쇄합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54e1a56-983e-4fb7-95e2-f1045d22bb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stream(stream):\n",
    "    for s in stream:\n",
    "        message = s[\"messages\"][-1]\n",
    "        if isinstance(message, tuple):\n",
    "            print(message)\n",
    "        else:\n",
    "            message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69a02d2-d337-40cd-ae33-52d168954345",
   "metadata": {},
   "source": [
    "다음으로 이전 노트북에서 생성한 sales.csv 파일에서 에이전트에게 제품 가격에 대해 물어보고 싶은 질문을 하나 이상 추가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93542a4-00e1-4778-801f-54000bedd21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of questions\n",
    "questions=[]\n",
    "questions.append(\"How much will it cost to buy 3 units of P002 and 5 units of P003?\")\n",
    "#questions.append(\"How many units of P010 can I buy with $200?\")\n",
    "#questions.append(\"Can I buy three units of P003 with $200? If not, how much more should I spend to get three units?\")\n",
    "#questions.append(\"Prices have gone up by 8%. How many units of P003 could I have purchased before the price increase with $140? How many can I buy after the price increase? Fractional units are not pssoible.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead2fdc8-7491-4b9b-a7b7-d4f7b909140b",
   "metadata": {},
   "source": [
    "추론에 포함된 단계를 이해하려면 추적을 활성화합니다. 그러나, 위 목록에서 **한 개의 질문을 제외한 모든 질문을 주석 처리**하여 추적 출력을 관리하기 쉽게 유지합니다. 또는 추적을 비활성화하고 모든 질문을 실행할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286029b4-a16c-405c-9280-961c1e9378a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_enabled=True\n",
    "\n",
    "if trace_enabled:\n",
    "    file_name=\"trace_\"+str(datetime.datetime.now())+\".txt\"\n",
    "    trace_handle=open(file_name, 'w')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f9e821-129a-4135-9969-6bc2bb7e2a1b",
   "metadata": {},
   "source": [
    "다음 셀에서 위 목록의 질문으로 에이전트를 호출합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba4fdd3-5e74-401a-8090-a3b95f68fc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message=\"Answer the following questions as best you can. Do not make up an answer. Think step by step. Do not perform intermediate math calculations on your own. Use the calculator tool provided for math calculations.\"\n",
    "\n",
    "for q in questions:\n",
    "    inputs = {\"messages\": [(\"system\",system_message), (\"user\", q)]}\n",
    "    config={\"recursion_limit\": 15}\n",
    "    print_stream(react_agent.stream(inputs, config, stream_mode=\"values\"))\n",
    "    print(\"\\n\"+\"================================ Answer complete =================================\"+\"\\n\")\n",
    "\n",
    "if trace_enabled:\n",
    "    trace_handle.close()"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "lcc_arn": "arn:aws:sagemaker:us-east-1:797620947747:studio-lifecycle-config/lcc-kernel"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}